{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-37JKjnDM8I",
        "outputId": "6fdf3387-692a-4642-d9b5-6b19d0a9be7b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "path = \"/content/drive/MyDrive/NLP_Project_New\"\n",
        "sys.path.append(os.path.abspath(path))"
      ],
      "metadata": {
        "id": "19hMaehfDPIp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TMn_pn4ADICX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import random\n",
        "import pandas as pd\n",
        "import nlp_project_functions as functions\n",
        "\n",
        "dir = f\"{path}/data/data_preprocessed\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts, labels = functions.read_conll_data(f\"{path}/data/train_test_val/train.tsv\")"
      ],
      "metadata": {
        "id": "svkJYDhiz4NH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sent_has_names(ls: list) -> bool:\n",
        "  ners = [\"B\", \"I\"]\n",
        "  if [s for s in ls if any(xs in s for xs in ners)]:\n",
        "    return True\n",
        "  else:\n",
        "    return False"
      ],
      "metadata": {
        "id": "ZF0YcoNo1Igm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTvH6Ct46giG",
        "outputId": "400af2c6-7cf2-458f-f207-92f23a20eb34"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23440"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [2, 4, 8, 16, 32, 64]:\n",
        "  subset = int(len(texts) / i)\n",
        "  no_ne_ratio = 3 * int(subset / 4) # 25% of sentences have to be names\n",
        "\n",
        "  nr = 0\n",
        "  no_ners = 0\n",
        "\n",
        "  subset_texts = []\n",
        "  subset_labels = []\n",
        "\n",
        "  for x, (text, label) in enumerate(zip(texts, labels)):\n",
        "    if nr == subset:\n",
        "      break\n",
        "    else:\n",
        "      if sent_has_names(label):\n",
        "        subset_texts.extend(text)\n",
        "        subset_texts.append(\"\")\n",
        "        subset_labels.extend(label)\n",
        "        subset_labels.append(\"\")\n",
        "        nr += 1\n",
        "      else:\n",
        "        if no_ners < no_ne_ratio:\n",
        "          subset_texts.extend(text)\n",
        "          subset_texts.append(\"\")\n",
        "          subset_labels.extend(label)\n",
        "          subset_labels.append(\"\")\n",
        "          no_ners += 1\n",
        "          nr += 1\n",
        "\n",
        "  train_smaller = pd.DataFrame(list(zip(subset_texts, subset_labels)))\n",
        "\n",
        "  #train_smaller.to_csv(f\"{path}/data/train_test_val/train_smaller/{i}_part_train.tsv\", sep=\"\\t\", index=False, header=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Far1z4IF0vNX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# General statistics about the dataset"
      ],
      "metadata": {
        "id": "El6l-W8cIUAA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. NE-to-token ratio"
      ],
      "metadata": {
        "id": "ugyBjtAZIfOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts, labels = functions.read_conll_data(f\"{path}/data/train_test_val/all_data.tsv\")\n",
        "all_labels = [x for xs in labels for x in xs]\n",
        "persons = [s for s in all_labels if s.endswith(\"PER\")]\n",
        "locations = [s for s in all_labels if s.endswith(\"LOC\")]\n",
        "\n",
        "ne = len(persons) + len(locations)\n",
        "ne_to_all = (ne/len(all_labels)) * 100\n",
        "all_ne_sentences = len([sent for sent in labels if sent_has_names(sent)])\n",
        "ne_sentences_to_all = (all_ne_sentences/len(labels)) * 100\n",
        "avg_sentence_length = len(all_labels)/len(labels)\n",
        "avg_ne_per_ne_sent = ne/all_ne_sentences\n",
        "print(f\"The complete corpus consists of {len(all_labels):,} tokens.\")\n",
        "print(f\"Of these, {len(persons):,} are names of individuals and {len(locations):,} are names of places. This makes for a total of {ne:,} named entities, or {ne_to_all:.2f}% of all tokens.\")\n",
        "print(f\"The complete corpus consists of {len(labels):,} sentences, of which {all_ne_sentences:,} (={ne_sentences_to_all:.2f}%) contain named entities.\")\n",
        "print(f\"The average sentence consists of {avg_sentence_length:.2f} words.\")\n",
        "print(f\"The sentences with named entities contain on average {avg_ne_per_ne_sent:.2f} named entities.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2VkpiRJIwsd",
        "outputId": "4acebb03-6eae-4cc8-fba7-ccfa9678876a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The complete corpus consists of 798,912 tokens.\n",
            "Of these, 12,364 are names of individuals and 3,382 are names of places. This makes for a total of 15,746 named entities, or 1.97% of all tokens.\n",
            "The complete corpus consists of 30,873 sentences, of which 7,198 (=23.31%) contain named entities.\n",
            "The average sentence consists of 25.88 words.\n",
            "The sentences with named entities contain on average 2.19 named entities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [\"train\", \"test\"]:\n",
        "  i_texts, i_labels = functions.read_conll_data(f\"{path}/data/train_test_val/{i}.tsv\")\n",
        "  i_all_labels = [x for xs in i_labels for x in xs]\n",
        "  i_persons = [s for s in i_all_labels if s.endswith(\"PER\")]\n",
        "  i_locations = [s for s in i_all_labels if s.endswith(\"LOC\")]\n",
        "\n",
        "  i_ne = len(i_persons) + len(i_locations)\n",
        "  i_ne_to_all = (i_ne/len(i_all_labels)) * 100\n",
        "  i_all_ne_sentences = len([sent for sent in i_labels if sent_has_names(sent)])\n",
        "  i_ne_sentences_to_all = (i_all_ne_sentences/len(i_labels)) * 100\n",
        "  i_avg_sentence_length = len(i_all_labels)/len(i_labels)\n",
        "  i_avg_ne_per_ne_sent = i_ne/i_all_ne_sentences\n",
        "\n",
        "  print(f\"The {i} corpus consists of {len(i_all_labels):,} tokens.\")\n",
        "  print(f\"Of these, {len(i_persons):,} are names of individuals and {len(i_locations):,} are names of places.\\nThis makes for a total of {i_ne:,} named entities, or {i_ne_to_all:.2f}% of all {i} tokens.\")\n",
        "  print(f\"The complete {i} corpus consists of {len(i_labels):,} sentences, of which {i_all_ne_sentences:,} (={i_ne_sentences_to_all:.2f}%) contain named entities.\")\n",
        "  print(f\"The average sentence in the {i} corpus consists of {i_avg_sentence_length:.2f} words.\")\n",
        "  print(f\"The sentences with named entities in the {i} corpus contain on average {i_avg_ne_per_ne_sent:.2f} named entities.\")\n",
        "  print(\"\\n=======\\n\")\n"
      ],
      "metadata": {
        "id": "7fppg35EQJqV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fea1f32-5d2e-4554-f5ab-ad3fad804615"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The train corpus consists of 638,813 tokens.\n",
            "Of these, 9,699 are names of individuals and 2,760 are names of places.\n",
            "This makes for a total of 12,459 named entities, or 1.95% of all train tokens.\n",
            "The complete train corpus consists of 23,440 sentences, of which 5,637 (=24.05%) contain named entities.\n",
            "The average sentence in the train corpus consists of 27.25 words.\n",
            "The sentences with named entities in the train corpus contain on average 2.21 named entities.\n",
            "\n",
            "=======\n",
            "\n",
            "The test corpus consists of 157,050 tokens.\n",
            "Of these, 2,450 are names of individuals and 619 are names of places.\n",
            "This makes for a total of 3,069 named entities, or 1.95% of all test tokens.\n",
            "The complete test corpus consists of 5,859 sentences, of which 1,436 (=24.51%) contain named entities.\n",
            "The average sentence in the test corpus consists of 26.80 words.\n",
            "The sentences with named entities in the test corpus contain on average 2.14 named entities.\n",
            "\n",
            "=======\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts, labels = functions.read_conll_data(f\"{path}/data/train_test_val/train_lessdense_names.tsv\")\n",
        "all_labels = [x for xs in labels for x in xs]\n",
        "persons = [s for s in all_labels if s.endswith(\"PER\")]\n",
        "locations = [s for s in all_labels if s.endswith(\"LOC\")]\n",
        "\n",
        "ne = len(persons) + len(locations)\n",
        "ne_to_all = (ne/len(all_labels)) * 100\n",
        "all_ne_sentences = len([sent for sent in labels if sent_has_names(sent)])\n",
        "ne_sentences_to_all = (all_ne_sentences/len(labels)) * 100\n",
        "avg_sentence_length = len(all_labels)/len(labels)\n",
        "avg_ne_per_ne_sent = ne/all_ne_sentences\n",
        "print(f\"The complete corpus consists of {len(all_labels):,} tokens.\")\n",
        "print(f\"Of these, {len(persons):,} are names of individuals and {len(locations):,} are names of places. This makes for a total of {ne:,} named entities, or {ne_to_all:.2f}% of all tokens.\")\n",
        "print(f\"The complete corpus consists of {len(labels):,} sentences, of which {all_ne_sentences:,} (={ne_sentences_to_all:.2f}%) contain named entities.\")\n",
        "print(f\"The average sentence consists of {avg_sentence_length:.2f} words.\")\n",
        "print(f\"The sentences with named entities contain on average {avg_ne_per_ne_sent:.2f} named entities.\")"
      ],
      "metadata": {
        "id": "88uOw56UowV1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ac73728-95da-4679-e412-a985144b1860"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The complete corpus consists of 232,464 tokens.\n",
            "Of these, 9,699 are names of individuals and 2,760 are names of places. This makes for a total of 12,459 named entities, or 5.36% of all tokens.\n",
            "The complete corpus consists of 6,197 sentences, of which 5,637 (=90.96%) contain named entities.\n",
            "The average sentence consists of 37.51 words.\n",
            "The sentences with named entities contain on average 2.21 named entities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create corpus with higher density of names\n",
        "\n",
        "texts, labels = functions.read_conll_data(f\"{path}/data/train_test_val/train.tsv\")\n",
        "\n",
        "#subset = int(len(texts) / 4)\n",
        "#no_ne_ratio = int(subset / 10) # 90% of sentences have to contain names\n",
        "\n",
        "no_ne_ratio = 560\n",
        "nr = 0\n",
        "no_ners = 0\n",
        "\n",
        "subset_texts = []\n",
        "subset_labels = []\n",
        "\n",
        "for x, (text, label) in enumerate(zip(texts, labels)):\n",
        "  #if nr == subset:\n",
        "  #  break\n",
        "  #else:\n",
        "  if sent_has_names(label):\n",
        "    subset_texts.extend(text)\n",
        "    subset_texts.append(\"\")\n",
        "    subset_labels.extend(label)\n",
        "    subset_labels.append(\"\")\n",
        "    nr += 1\n",
        "  else:\n",
        "    if no_ners < no_ne_ratio:\n",
        "      subset_texts.extend(text)\n",
        "      subset_texts.append(\"\")\n",
        "      subset_labels.extend(label)\n",
        "      subset_labels.append(\"\")\n",
        "      no_ners += 1\n",
        "      nr += 1\n",
        "\n",
        "train_dense = pd.DataFrame(list(zip(subset_texts, subset_labels)))\n",
        "\n",
        "print(len(texts))\n",
        "print(nr)\n",
        "print(len(train_dense))"
      ],
      "metadata": {
        "id": "0ZlHs0Gr4L7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dense.to_csv(f\"{path}/data/train_test_val/train_lessdense_names.tsv\", sep=\"\\t\", index=False, header=False)"
      ],
      "metadata": {
        "id": "rSGaSu6a6Kt8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}